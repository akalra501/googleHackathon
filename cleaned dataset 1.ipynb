{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d2039c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc4d9c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top by LOGO churn share:\n",
      "sales_segment  customers  churned_customers  logo_churn_share  logo_churn_rate\n",
      "   SMB_Inside       1320                217          0.596154         0.164394\n",
      "    SMB_Field        574                 97          0.266484         0.168990\n",
      "    MidMarket        632                 29          0.079670         0.045886\n",
      "   Enterprise        474                 21          0.057692         0.044304\n",
      "\n",
      "Top by ACV churn share:\n",
      "sales_segment   total_acv  churned_acv  acv_churn_share  acv_churn_rate\n",
      "   Enterprise 84265245.37   3666669.15         0.701746        0.043513\n",
      "    MidMarket 15870773.45    743722.20         0.142337        0.046861\n",
      "   SMB_Inside  5436775.50    595852.90         0.114037        0.109597\n",
      "    SMB_Field  2260570.77    218822.49         0.041879        0.096800\n",
      "\n",
      "Decision helper:\n",
      "Top logo segment: SMB_Inside\n",
      "Top ACV segment : Enterprise\n"
     ]
    }
   ],
   "source": [
    "# To decide churn metric as LOGO or ACV\n",
    "\n",
    "df = pd.read_csv(\"dataset1.csv\")  \n",
    "\n",
    "SEG_COL = \"sales_segment\"   # try: \"sales_segment\", \"product_tier\", \"company_size_bucket\", \"region\", \"acquisition_channel\", \"is_eu\", \"industry\"\n",
    "\n",
    "ID_COL    = \"customer_id\"\n",
    "CHURN_COL = \"is_churned\"              \n",
    "ACV_COL   = \"annual_contract_value\"   \n",
    "\n",
    "df[SEG_COL] = df[SEG_COL].fillna(\"Unknown\")\n",
    "df[CHURN_COL] = pd.to_numeric(df[CHURN_COL], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[ACV_COL] = pd.to_numeric(df[ACV_COL], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "churned = df[df[CHURN_COL] == 1].copy()\n",
    "total_churned_logos = churned[ID_COL].nunique()\n",
    "total_churned_acv   = churned[ACV_COL].sum()\n",
    "\n",
    "summary = (\n",
    "    df.groupby(SEG_COL, dropna=False)\n",
    "      .agg(customers=(ID_COL, \"nunique\"),\n",
    "           churned_customers=(CHURN_COL, \"sum\"),\n",
    "           total_acv=(ACV_COL, \"sum\"))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "churn_by_seg = (\n",
    "    churned.groupby(SEG_COL, dropna=False)\n",
    "           .agg(churned_acv=(ACV_COL, \"sum\"))\n",
    "           .reset_index()\n",
    ")\n",
    "\n",
    "summary = summary.merge(churn_by_seg, on=SEG_COL, how=\"left\").fillna({\"churned_acv\": 0.0})\n",
    "\n",
    "summary[\"logo_churn_rate\"] = summary[\"churned_customers\"] / summary[\"customers\"]\n",
    "summary[\"acv_churn_rate\"]  = summary[\"churned_acv\"] / summary[\"total_acv\"].replace({0: pd.NA})\n",
    "\n",
    "summary[\"logo_churn_share\"] = summary[\"churned_customers\"] / (total_churned_logos if total_churned_logos else 1)\n",
    "summary[\"acv_churn_share\"]  = summary[\"churned_acv\"] / (total_churned_acv if total_churned_acv else 1)\n",
    "\n",
    "logo_top = summary.sort_values(\"logo_churn_share\", ascending=False).head(10)\n",
    "acv_top  = summary.sort_values(\"acv_churn_share\",  ascending=False).head(10)\n",
    "\n",
    "print(\"Top by LOGO churn share:\")\n",
    "print(logo_top[[SEG_COL, \"customers\", \"churned_customers\", \"logo_churn_share\", \"logo_churn_rate\"]].to_string(index=False))\n",
    "\n",
    "print(\"\\nTop by ACV churn share:\")\n",
    "print(acv_top[[SEG_COL, \"total_acv\", \"churned_acv\", \"acv_churn_share\", \"acv_churn_rate\"]].to_string(index=False))\n",
    "\n",
    "top_logo_seg = logo_top.iloc[0][SEG_COL] if len(logo_top) else None\n",
    "top_acv_seg  = acv_top.iloc[0][SEG_COL]  if len(acv_top)  else None\n",
    "print(\"\\nDecision helper:\")\n",
    "print(\"Top logo segment:\", top_logo_seg)\n",
    "print(\"Top ACV segment :\", top_acv_seg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17c0f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing counts (top):\n",
      "contract_end_date           1428\n",
      "industry                     862\n",
      "customer_id                    0\n",
      "sales_segment                  0\n",
      "initial_onboarding_score       0\n",
      "dtype: int64\n",
      "\n",
      "Industry missing after fix: 0\n",
      "industry\n",
      "Unknown                  862\n",
      "Ecommerce                278\n",
      "Hospitality              275\n",
      "Healthcare               273\n",
      "Logistics                268\n",
      "Professional Services    264\n",
      "Wholesale                261\n",
      "Manufacturing            261\n",
      "Retail                   258\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dataset 1 cleaning and preprocessing\n",
    "df1 = pd.read_csv(\"dataset1.csv\") \n",
    "\n",
    "# Checking missingness\n",
    "missing_counts = df1.isna().sum().sort_values(ascending=False)\n",
    "missing_rates = (df1.isna().mean()*100).round(2).sort_values(ascending=False)\n",
    "\n",
    "print(\"Missing counts (top):\")\n",
    "print(missing_counts.head(5))\n",
    "\n",
    "''' Missing counts (top):\n",
    "contract_end_date           1428\n",
    "industry                     862 '''\n",
    "\n",
    "df1.loc[df1[\"industry\"].isna(), [\"customer_id\",\"company_name\",\"country\",\"region\",\"industry\"]].head(20)\n",
    "\n",
    "df1[\"industry_is_missing\"] = df1[\"industry\"].isna()\n",
    "df1[\"industry\"] = df1[\"industry\"].fillna(\"Unknown\")\n",
    "\n",
    "print(\"\\nIndustry missing after fix:\", df1[\"industry\"].isna().sum())\n",
    "print(df1[\"industry\"].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "521bf63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_size_bucket\n",
      "10-Jan      1035\n",
      "Nov-50       859\n",
      "51-200       632\n",
      "201-1000     307\n",
      "1000+        167\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fixed rows: 1894\n",
      "company_size_bucket\n",
      "1-10        1035\n",
      "11-50        859\n",
      "51-200       632\n",
      "201-1000     307\n",
      "1000+        167\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# fixing company_size_bucket: common Excel auto-date formatting issues in this file \n",
    "print(df1[\"company_size_bucket\"].value_counts())\n",
    "\n",
    "SIZE_BUCKET_FIX = {\"10-Jan\": \"1-10\", \"Nov-50\": \"11-50\"}\n",
    "VALID_BUCKETS = {\"1-10\",\"11-50\",\"51-200\",\"201-1000\",\"1000+\"}\n",
    "\n",
    "df1[\"company_size_bucket_original\"] = df1[\"company_size_bucket\"]\n",
    "df1[\"company_size_bucket\"] = df1[\"company_size_bucket\"].replace(SIZE_BUCKET_FIX)\n",
    "\n",
    "df1[\"company_size_bucket_was_fixed\"] = (\n",
    "    df1[\"company_size_bucket_original\"].notna()\n",
    "    & (df1[\"company_size_bucket_original\"] != df1[\"company_size_bucket\"])\n",
    ")\n",
    "\n",
    "print(\"\\nFixed rows:\", int(df1[\"company_size_bucket_was_fixed\"].sum()))\n",
    "print(df1[\"company_size_bucket\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "681e309d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing start dates: 0\n",
      "Missing end dates: 1428\n",
      "End before start: 0\n",
      "has_missing_contract_end_date  False  True \n",
      "renewed_flag                               \n",
      "0                               1572      0\n",
      "1                                  0   1428\n",
      "has_missing_contract_end_date  False  True \n",
      "is_churned                                 \n",
      "0                               1208   1428\n",
      "1                                364      0\n",
      "\n",
      "Contract term (days) stats:\n",
      "count    1572.000000\n",
      "mean      299.603053\n",
      "std        99.361937\n",
      "min        91.000000\n",
      "25%       183.000000\n",
      "50%       366.000000\n",
      "75%       366.000000\n",
      "max       366.000000\n",
      "Name: contract_term_days, dtype: float64\n",
      "\n",
      "Most common terms: contract_term_days\n",
      "366.0    1068\n",
      "183.0     372\n",
      "91.0      132\n",
      "Name: count, dtype: int64\n",
      "Churned but missing end date: 0\n",
      "Churned but not early termination: 69\n",
      "Violation counts with renewed_flag==0 and is_churned==1: 69\n"
     ]
    }
   ],
   "source": [
    "# ---- A1) Parse dates\n",
    "df1[\"contract_start_dt\"] = pd.to_datetime(df1[\"contract_start_date\"], errors=\"coerce\")\n",
    "df1[\"contract_end_dt\"]   = pd.to_datetime(df1[\"contract_end_date\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Missing start dates:\", df1[\"contract_start_dt\"].isna().sum())\n",
    "print(\"Missing end dates:\", df1[\"contract_end_dt\"].isna().sum())\n",
    "\n",
    "df1[\"end_before_start\"] = (\n",
    "    df1[\"contract_start_dt\"].notna()\n",
    "    & df1[\"contract_end_dt\"].notna()\n",
    "    & (df1[\"contract_end_dt\"] < df1[\"contract_start_dt\"])\n",
    ")\n",
    "print(\"End before start:\", int(df1[\"end_before_start\"].sum()))\n",
    "\n",
    "df1[\"has_missing_contract_end_date\"] = df1[\"contract_end_dt\"].isna()\n",
    "\n",
    "print(pd.crosstab(df1[\"renewed_flag\"], df1[\"has_missing_contract_end_date\"]))\n",
    "print(pd.crosstab(df1[\"is_churned\"], df1[\"has_missing_contract_end_date\"]))\n",
    "\n",
    "# Contract term in days (only where end exists)\n",
    "df1[\"contract_term_days\"] = (df1[\"contract_end_dt\"] - df1[\"contract_start_dt\"]).dt.days\n",
    "\n",
    "print(\"\\nContract term (days) stats:\")\n",
    "print(df1[\"contract_term_days\"].describe())\n",
    "\n",
    "print(\"\\nMost common terms:\", df1[\"contract_term_days\"].value_counts().head(10))\n",
    "\n",
    "df1[\"violation_churn_missing_end_date\"] = (df1[\"is_churned\"] == 1) & df1[\"contract_end_dt\"].isna()\n",
    "\n",
    "# If churned but term >= ~12 months, that contradicts \"early termination\"\n",
    "df1[\"violation_churn_not_early_term\"] = (\n",
    "    (df1[\"is_churned\"] == 1)\n",
    "    & df1[\"contract_term_days\"].notna()\n",
    "    & (df1[\"contract_term_days\"] >= 365)\n",
    ")\n",
    "\n",
    "print(\"Churned but missing end date:\", int(df1[\"violation_churn_missing_end_date\"].sum()))\n",
    "print(\"Churned but not early termination:\", int(df1[\"violation_churn_not_early_term\"].sum()))\n",
    "\n",
    "# view the rows if any violations exist\n",
    "df1.loc[df1[\"violation_churn_not_early_term\"],\n",
    "        [\"customer_id\",\"contract_start_date\",\"contract_end_date\",\"contract_term_days\",\"renewed_flag\",\"is_churned\"]].head(20)\n",
    "\n",
    "# print violation counts with renewed_flag==0 and is_churned==1\n",
    "print(\"Violation counts with renewed_flag==0 and is_churned==1:\",   \n",
    "      int(df1[(df1[\"violation_churn_not_early_term\"]) & (df1[\"renewed_flag\"] == 0) & (df1[\"is_churned\"] == 1)].shape[0])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16165f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid acquisition_channel: 0\n",
      "EU-region mismatches: 0\n",
      "ACV invalid: 0\n",
      "Discount invalid: 0\n",
      "Onboarding invalid: 0\n",
      "Duplicate customer_id: 0\n"
     ]
    }
   ],
   "source": [
    "valid_channels = {\"Inbound\",\"Outbound\",\"Partner\",\"SelfServe\"}\n",
    "df1[\"acquisition_channel_invalid\"] = df1[\"acquisition_channel\"].notna() & ~df1[\"acquisition_channel\"].isin(valid_channels)\n",
    "print(\"Invalid acquisition_channel:\", int(df1[\"acquisition_channel_invalid\"].sum()))\n",
    "df1.loc[df1[\"acquisition_channel_invalid\"], [\"customer_id\",\"acquisition_channel\"]].head(10)\n",
    "\n",
    "# EU consistency check\n",
    "df1[\"eu_region_mismatch\"] = (\n",
    "    (df1[\"region\"].notna()) &\n",
    "    (((df1[\"is_eu\"] == 1) & (df1[\"region\"] != \"Europe\")) |\n",
    "     ((df1[\"is_eu\"] == 0) & (df1[\"region\"] == \"Europe\")))\n",
    ")\n",
    "print(\"EU-region mismatches:\", int(df1[\"eu_region_mismatch\"].sum()))\n",
    "\n",
    "df1[\"acv_invalid\"] = df1[\"annual_contract_value\"].notna() & (df1[\"annual_contract_value\"] <= 0)\n",
    "df1[\"discount_invalid\"] = df1[\"discount_pct\"].notna() & ~df1[\"discount_pct\"].between(0, 1)\n",
    "df1[\"onboarding_invalid\"] = df1[\"initial_onboarding_score\"].notna() & ~df1[\"initial_onboarding_score\"].between(0, 10)\n",
    "\n",
    "print(\"ACV invalid:\", int(df1[\"acv_invalid\"].sum()))\n",
    "print(\"Discount invalid:\", int(df1[\"discount_invalid\"].sum()))\n",
    "print(\"Onboarding invalid:\", int(df1[\"onboarding_invalid\"].sum()))\n",
    "\n",
    "print(\"Duplicate customer_id:\", int(df1[\"customer_id\"].duplicated().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ffcbf9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'company_name', 'country', 'region', 'is_eu', 'industry',\n",
       "       'company_size_bucket', 'annual_contract_value', 'product_tier',\n",
       "       'sales_segment', 'acquisition_channel', 'contract_start_date',\n",
       "       'contract_end_date', 'renewed_flag', 'discount_pct',\n",
       "       'initial_onboarding_score', 'is_churned', 'industry_is_missing',\n",
       "       'contract_start_dt', 'contract_end_dt', 'has_missing_contract_end_date',\n",
       "       'contract_term_days', 'violation_churn_not_early_term'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()\n",
    "df1.columns\n",
    "cols_to_drop = [\n",
    "    \"company_size_bucket_original\",\n",
    "    \"company_size_bucket_was_fixed\",\n",
    "    \"end_before_start\",\n",
    "    \"violation_churn_missing_end_date\",\n",
    "    \"acquisition_channel_invalid\",\n",
    "    \"eu_region_mismatch\",\n",
    "    \"acv_invalid\",\n",
    "    \"discount_invalid\",\n",
    "    \"onboarding_invalid\",\n",
    "]\n",
    "\n",
    "# only drop columns that actually exist (safe)\n",
    "df1.drop(columns=[c for c in cols_to_drop if c in df1.columns], inplace=True)\n",
    "\n",
    "df1.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
